<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">

<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>LCOV - cov.info - stablehlo/dialect/Base.cpp</title>
  <link rel="stylesheet" type="text/css" href="../../gcov.css">
</head>

<body>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="title">LCOV - code coverage report</td></tr>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>

    <tr>
      <td width="100%">
        <table cellpadding=1 border=0 width="100%">
          <tr>
            <td width="10%" class="headerItem">Current view:</td>
            <td width="35%" class="headerValue"><a href="../../index.html">top level</a> - <a href="index.html">stablehlo/dialect</a> - Base.cpp<span style="font-size: 80%;"> (source / <a href="Base.cpp.func-sort-c.html">functions</a>)</span></td>
            <td width="5%"></td>
            <td width="15%"></td>
            <td width="10%" class="headerCovTableHead">Hit</td>
            <td width="10%" class="headerCovTableHead">Total</td>
            <td width="15%" class="headerCovTableHead">Coverage</td>
          </tr>
          <tr>
            <td class="headerItem">Test:</td>
            <td class="headerValue">cov.info</td>
            <td></td>
            <td class="headerItem">Lines:</td>
            <td class="headerCovTableEntry">263</td>
            <td class="headerCovTableEntry">283</td>
            <td class="headerCovTableEntryHi">92.9 %</td>
          </tr>
          <tr>
            <td class="headerItem">Date:</td>
            <td class="headerValue">2023-04-19 16:01:34</td>
            <td></td>
            <td class="headerItem">Functions:</td>
            <td class="headerCovTableEntry">22</td>
            <td class="headerCovTableEntry">23</td>
            <td class="headerCovTableEntryHi">95.7 %</td>
          </tr>
          <tr><td><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
        </table>
      </td>
    </tr>

    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
  </table>

  <table cellpadding=0 cellspacing=0 border=0>
    <tr>
      <td><br></td>
    </tr>
    <tr>
      <td>
<pre class="sourceHeading">          Line data    Source code</pre>
<pre class="source">
<a name="1"><span class="lineNum">       1 </span>            : /* Copyright 2020 The TensorFlow Authors. All Rights Reserved.</a>
<a name="2"><span class="lineNum">       2 </span>            :    Copyright 2022 The StableHLO Authors.</a>
<a name="3"><span class="lineNum">       3 </span>            : </a>
<a name="4"><span class="lineNum">       4 </span>            : Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</a>
<a name="5"><span class="lineNum">       5 </span>            : you may not use this file except in compliance with the License.</a>
<a name="6"><span class="lineNum">       6 </span>            : You may obtain a copy of the License at</a>
<a name="7"><span class="lineNum">       7 </span>            : </a>
<a name="8"><span class="lineNum">       8 </span>            :     http://www.apache.org/licenses/LICENSE-2.0</a>
<a name="9"><span class="lineNum">       9 </span>            : </a>
<a name="10"><span class="lineNum">      10 </span>            : Unless required by applicable law or agreed to in writing, software</a>
<a name="11"><span class="lineNum">      11 </span>            : distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</a>
<a name="12"><span class="lineNum">      12 </span>            : WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</a>
<a name="13"><span class="lineNum">      13 </span>            : See the License for the specific language governing permissions and</a>
<a name="14"><span class="lineNum">      14 </span>            : limitations under the License.</a>
<a name="15"><span class="lineNum">      15 </span>            : ==============================================================================*/</a>
<a name="16"><span class="lineNum">      16 </span>            : </a>
<a name="17"><span class="lineNum">      17 </span>            : #include &quot;stablehlo/dialect/Base.h&quot;</a>
<a name="18"><span class="lineNum">      18 </span>            : </a>
<a name="19"><span class="lineNum">      19 </span>            : #include &lt;optional&gt;</a>
<a name="20"><span class="lineNum">      20 </span>            : </a>
<a name="21"><span class="lineNum">      21 </span>            : #include &quot;llvm/ADT/STLExtras.h&quot;</a>
<a name="22"><span class="lineNum">      22 </span>            : #include &quot;llvm/ADT/TypeSwitch.h&quot;</a>
<a name="23"><span class="lineNum">      23 </span>            : #include &quot;mlir/Dialect/Quant/QuantTypes.h&quot;</a>
<a name="24"><span class="lineNum">      24 </span>            : #include &quot;mlir/Dialect/Shape/IR/Shape.h&quot;</a>
<a name="25"><span class="lineNum">      25 </span>            : #include &quot;mlir/IR/DialectImplementation.h&quot;</a>
<a name="26"><span class="lineNum">      26 </span>            : #include &quot;mlir/IR/TypeUtilities.h&quot;</a>
<a name="27"><span class="lineNum">      27 </span>            : #include &quot;mlir/Support/LLVM.h&quot;</a>
<a name="28"><span class="lineNum">      28 </span>            : </a>
<a name="29"><span class="lineNum">      29 </span>            : // Include order matters</a>
<a name="30"><span class="lineNum">      30 </span>            : #include &quot;stablehlo/dialect/BaseAttrInterfaces.cpp.inc&quot;</a>
<a name="31"><span class="lineNum">      31 </span>            : </a>
<a name="32"><span class="lineNum">      32 </span>            : namespace mlir {</a>
<a name="33"><span class="lineNum">      33 </span>            : namespace hlo {</a>
<a name="34"><span class="lineNum">      34 </span>            : </a>
<a name="35"><span class="lineNum">      35 </span>            : namespace {</a>
<a name="36"><span class="lineNum">      36 </span><span class="lineCov">    4626415 : Type getExpressedTypeOrSelf(Type type) {</span></a>
<a name="37"><span class="lineNum">      37 </span><span class="lineCov">    4626415 :   auto quantType = type.dyn_cast&lt;quant::QuantizedType&gt;();</span></a>
<a name="38"><span class="lineNum">      38 </span><span class="lineCov">    4626415 :   return quantType ? quantType.getExpressedType() : type;</span></a>
<a name="39"><span class="lineNum">      39 </span><span class="lineCov">    4626415 : }</span></a>
<a name="40"><span class="lineNum">      40 </span>            : }  // namespace</a>
<a name="41"><span class="lineNum">      41 </span>            : </a>
<a name="42"><span class="lineNum">      42 </span><span class="lineCov">    2317234 : LogicalResult verifyCompatibleShapeWithBounds(Type type1, Type type2) {</span></a>
<a name="43"><span class="lineNum">      43 </span><span class="lineCov">    2317234 :   if (failed(verifyCompatibleShape(type1, type2))) return failure();</span></a>
<a name="44"><span class="lineNum">      44 </span>            : </a>
<a name="45"><span class="lineNum">      45 </span>            :   // Verify shapes against bounds</a>
<a name="46"><span class="lineNum">      46 </span><span class="lineCov">    6946691 :   auto isCompatible = [](ArrayRef&lt;int64_t&gt; shape,</span></a>
<a name="47"><span class="lineNum">      47 </span><span class="lineCov">    4629494 :                          BoundedAttrInterface boundedAttr) {</span></a>
<a name="48"><span class="lineNum">      48 </span><span class="lineCov">    4629494 :     if (shape.empty() || !boundedAttr) return true;</span></a>
<a name="49"><span class="lineNum">      49 </span><span class="lineCov">        250 :     auto bounds = boundedAttr.getBounds();</span></a>
<a name="50"><span class="lineNum">      50 </span><span class="lineCov">        940 :     for (auto [dim_size, bound] : llvm::zip(shape, bounds))  // NOLINT</span></a>
<a name="51"><span class="lineNum">      51 </span><span class="lineCov">        690 :       if (!isDynamicDimSize(bound) &amp;&amp; bound &lt; dim_size) return false;</span></a>
<a name="52"><span class="lineNum">      52 </span><span class="lineCov">        248 :     return true;</span></a>
<a name="53"><span class="lineNum">      53 </span><span class="lineCov">    4629494 :   };</span></a>
<a name="54"><span class="lineNum">      54 </span>            : </a>
<a name="55"><span class="lineNum">      55 </span><span class="lineCov">    2317197 :   RankedTensorType rankedType1 = type1.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="56"><span class="lineNum">      56 </span><span class="lineCov">    2317197 :   RankedTensorType rankedType2 = type2.dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="57"><span class="lineNum">      57 </span><span class="lineCov">    2317197 :   if (rankedType1 &amp;&amp; rankedType2) {</span></a>
<a name="58"><span class="lineNum">      58 </span><span class="lineCov">    2316099 :     auto boundedAttr1 =</span></a>
<a name="59"><span class="lineNum">      59 </span><span class="lineCov">    2316099 :         rankedType1.getEncoding().dyn_cast_or_null&lt;BoundedAttrInterface&gt;();</span></a>
<a name="60"><span class="lineNum">      60 </span><span class="lineCov">    2316099 :     auto boundedAttr2 =</span></a>
<a name="61"><span class="lineNum">      61 </span><span class="lineCov">    2316099 :         rankedType2.getEncoding().dyn_cast_or_null&lt;BoundedAttrInterface&gt;();</span></a>
<a name="62"><span class="lineNum">      62 </span><span class="lineCov">    2316099 :     return LogicalResult::success(</span></a>
<a name="63"><span class="lineNum">      63 </span><span class="lineCov">    2316099 :         isCompatible(rankedType1.getShape(), boundedAttr2) &amp;&amp;</span></a>
<a name="64"><span class="lineNum">      64 </span><span class="lineCov">    2315768 :         isCompatible(rankedType2.getShape(), boundedAttr1));</span></a>
<a name="65"><span class="lineNum">      65 </span><span class="lineCov">    2316099 :   }</span></a>
<a name="66"><span class="lineNum">      66 </span><span class="lineCov">       1098 :   return success();</span></a>
<a name="67"><span class="lineNum">      67 </span><span class="lineCov">    2315774 : }</span></a>
<a name="68"><span class="lineNum">      68 </span>            : </a>
<a name="69"><span class="lineNum">      69 </span><span class="lineCov">    4626650 : bool isCompatibleForHloTypeInference(Type tp1, Type tp2) {</span></a>
<a name="70"><span class="lineNum">      70 </span>            :   // Dynamism: We don't require shapes to be the same, we only require them</a>
<a name="71"><span class="lineNum">      71 </span>            :   // to be compatible, which means that:</a>
<a name="72"><span class="lineNum">      72 </span>            :   //   1) At least one of the shapes is unranked.</a>
<a name="73"><span class="lineNum">      73 </span>            :   //   2) Or both shapes have the same rank and their dimensions are compatible,</a>
<a name="74"><span class="lineNum">      74 </span>            :   //     i.e. for each pair of corresponding dimensions:</a>
<a name="75"><span class="lineNum">      75 </span>            :   //       2.1) At least one of the dimensions is dynamic,</a>
<a name="76"><span class="lineNum">      76 </span>            :   //       2.2) Or both dimensions are equal.</a>
<a name="77"><span class="lineNum">      77 </span>            :   // These relaxed rules simplify the implementation of type inference, allowing</a>
<a name="78"><span class="lineNum">      78 </span>            :   // ops with partially inferred types to pass verification.</a>
<a name="79"><span class="lineNum">      79 </span><span class="lineCov">    4626650 :   auto stp1 = tp1.dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="80"><span class="lineNum">      80 </span><span class="lineCov">    4626650 :   auto stp2 = tp2.dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="81"><span class="lineNum">      81 </span><span class="lineCov">    4626650 :   if (stp1 &amp;&amp; stp2)</span></a>
<a name="82"><span class="lineNum">      82 </span><span class="lineCov">    2316414 :     return succeeded(verifyCompatibleShapeWithBounds(stp1, stp2)) &amp;&amp;</span></a>
<a name="83"><span class="lineNum">      83 </span><span class="lineCov">    4631304 :            isCompatibleForHloTypeInference(stp1.getElementType(),</span></a>
<a name="84"><span class="lineNum">      84 </span><span class="lineCov">    2315652 :                                            stp2.getElementType());</span></a>
<a name="85"><span class="lineNum">      85 </span>            : </a>
<a name="86"><span class="lineNum">      86 </span>            :   // Quantization: In the most general case, we allow any combination of</a>
<a name="87"><span class="lineNum">      87 </span>            :   // quantized/non-quantized across any combination of operands/results,</a>
<a name="88"><span class="lineNum">      88 </span>            :   // and some differences in quantization parameters across operands/results.</a>
<a name="89"><span class="lineNum">      89 </span>            :   // Individual ops may introduce additional constraints.</a>
<a name="90"><span class="lineNum">      90 </span><span class="lineCov">    2315562 :   auto qtp1 = tp1.dyn_cast&lt;quant::QuantizedType&gt;();</span></a>
<a name="91"><span class="lineNum">      91 </span><span class="lineCov">    2315562 :   auto qtp2 = tp2.dyn_cast&lt;quant::QuantizedType&gt;();</span></a>
<a name="92"><span class="lineNum">      92 </span><span class="lineCov">    2315562 :   if (qtp1 &amp;&amp; qtp2) {</span></a>
<a name="93"><span class="lineNum">      93 </span><span class="lineCov">        141 :     if (qtp1.getStorageType() != qtp2.getStorageType() ||</span></a>
<a name="94"><span class="lineNum">      94 </span><span class="lineCov">         70 :         qtp1.getStorageTypeMin() != qtp2.getStorageTypeMin() ||</span></a>
<a name="95"><span class="lineNum">      95 </span><span class="lineCov">         69 :         qtp1.getStorageTypeMax() != qtp2.getStorageTypeMax())</span></a>
<a name="96"><span class="lineNum">      96 </span><span class="lineCov">          2 :       return false;</span></a>
<a name="97"><span class="lineNum">      97 </span><span class="lineCov">         69 :   }</span></a>
<a name="98"><span class="lineNum">      98 </span><span class="lineCov">    2315560 :   auto etp1 = getExpressedTypeOrSelf(tp1);</span></a>
<a name="99"><span class="lineNum">      99 </span><span class="lineCov">    2315560 :   auto etp2 = getExpressedTypeOrSelf(tp2);</span></a>
<a name="100"><span class="lineNum">     100 </span>            : </a>
<a name="101"><span class="lineNum">     101 </span>            :   // Sparsity: In the most general case, we allow any combination of</a>
<a name="102"><span class="lineNum">     102 </span>            :   // sparsity/denseness across any combination of operands/results, as well as</a>
<a name="103"><span class="lineNum">     103 </span>            :   // differences in sparsity encodings for operands and results.</a>
<a name="104"><span class="lineNum">     104 </span>            :   // Individual ops may introduce additional constraints.</a>
<a name="105"><span class="lineNum">     105 </span>            :   // No additional code is needed to check this because of how sparsity is</a>
<a name="106"><span class="lineNum">     106 </span>            :   // currently implemented.</a>
<a name="107"><span class="lineNum">     107 </span>            : </a>
<a name="108"><span class="lineNum">     108 </span>            :   // Default case: Unless dynamism, quantization and/or sparsity are involved,</a>
<a name="109"><span class="lineNum">     109 </span>            :   // the types are required to be exactly equal.</a>
<a name="110"><span class="lineNum">     110 </span><span class="lineCov">    2315560 :   return etp1 == etp2;</span></a>
<a name="111"><span class="lineNum">     111 </span><span class="lineCov">    4630452 : }</span></a>
<a name="112"><span class="lineNum">     112 </span>            : </a>
<a name="113"><span class="lineNum">     113 </span><span class="lineCov">     910189 : bool isCompatibleForHloTypeInference(TypeRange tp1, TypeRange tp2) {</span></a>
<a name="114"><span class="lineNum">     114 </span><span class="lineCov">     910189 :   if (tp1.size() != tp2.size()) return false;</span></a>
<a name="115"><span class="lineNum">     115 </span><span class="lineCov">    1936958 :   for (auto [lt, rt] : llvm::zip(tp1, tp2))</span></a>
<a name="116"><span class="lineNum">     116 </span><span class="lineCov">    2053554 :     if (!isCompatibleForHloTypeInference(lt, rt)) return false;</span></a>
<a name="117"><span class="lineNum">     117 </span><span class="lineCov">     908574 :   return true;</span></a>
<a name="118"><span class="lineNum">     118 </span><span class="lineCov">     910189 : }</span></a>
<a name="119"><span class="lineNum">     119 </span>            : </a>
<a name="120"><span class="lineNum">     120 </span><span class="lineNoCov">          0 : bool isCompatibleForHloTypeInference(ArrayRef&lt;int64_t&gt; shape1, Type tp2) {</span></a>
<a name="121"><span class="lineNum">     121 </span><span class="lineNoCov">          0 :   auto stp2 = tp2.dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="122"><span class="lineNum">     122 </span><span class="lineNoCov">          0 :   if (!stp2) return false;</span></a>
<a name="123"><span class="lineNum">     123 </span><span class="lineNoCov">          0 :   return isCompatibleForHloTypeInference(</span></a>
<a name="124"><span class="lineNum">     124 </span><span class="lineNoCov">          0 :       RankedTensorType::get(shape1, stp2.getElementType()), tp2);</span></a>
<a name="125"><span class="lineNum">     125 </span><span class="lineNoCov">          0 : }</span></a>
<a name="126"><span class="lineNum">     126 </span>            : </a>
<a name="127"><span class="lineNum">     127 </span><span class="lineCov">      19224 : bool isCompatibleForHloTypeInference(Value shape1, Type tp2) {</span></a>
<a name="128"><span class="lineNum">     128 </span><span class="lineCov">      19224 :   SmallVector&lt;int64_t&gt; shapeVec1;</span></a>
<a name="129"><span class="lineNum">     129 </span><span class="lineCov">      19224 :   if (!succeeded(matchInts(shape1, shapeVec1))) return true;</span></a>
<a name="130"><span class="lineNum">     130 </span><span class="lineCov">        127 :   if (llvm::any_of(shapeVec1, [&amp;](int64_t x) { return x &lt; 0; })) return false;</span></a>
<a name="131"><span class="lineNum">     131 </span><span class="lineCov">         45 :   auto stp2 = tp2.dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="132"><span class="lineNum">     132 </span><span class="lineCov">         45 :   if (!stp2) return false;</span></a>
<a name="133"><span class="lineNum">     133 </span><span class="lineCov">         45 :   auto tp1 = RankedTensorType::get(shapeVec1, stp2.getElementType());</span></a>
<a name="134"><span class="lineNum">     134 </span><span class="lineCov">         45 :   return isCompatibleForHloTypeInference(tp1, tp2);</span></a>
<a name="135"><span class="lineNum">     135 </span><span class="lineCov">      19224 : }</span></a>
<a name="136"><span class="lineNum">     136 </span>            : </a>
<a name="137"><span class="lineNum">     137 </span><span class="lineCov">          2 : LogicalResult deriveShapeFromOperand(</span></a>
<a name="138"><span class="lineNum">     138 </span>            :     OpBuilder* builder, Operation* op, Value operand,</a>
<a name="139"><span class="lineNum">     139 </span><span class="lineCov">          2 :     SmallVectorImpl&lt;Value&gt;* reifiedReturnShapes) {</span></a>
<a name="140"><span class="lineNum">     140 </span><span class="lineCov">          2 :   auto shapedTy = operand.getType().dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="141"><span class="lineNum">     141 </span><span class="lineCov">          2 :   if (!shapedTy) {</span></a>
<a name="142"><span class="lineNum">     142 </span><span class="lineNoCov">          0 :     op-&gt;emitOpError() &lt;&lt; &quot;operand is not a shaped type&quot;;</span></a>
<a name="143"><span class="lineNum">     143 </span><span class="lineNoCov">          0 :     return failure();</span></a>
<a name="144"><span class="lineNum">     144 </span>            :   }</a>
<a name="145"><span class="lineNum">     145 </span><span class="lineCov">          4 :   reifiedReturnShapes-&gt;assign(</span></a>
<a name="146"><span class="lineNum">     146 </span><span class="lineCov">          2 :       {builder-&gt;create&lt;shape::ShapeOfOp&gt;(op-&gt;getLoc(), operand)});</span></a>
<a name="147"><span class="lineNum">     147 </span><span class="lineCov">          2 :   return success();</span></a>
<a name="148"><span class="lineNum">     148 </span><span class="lineCov">          2 : }</span></a>
<a name="149"><span class="lineNum">     149 </span>            : </a>
<a name="150"><span class="lineNum">     150 </span><span class="lineCov">      12772 : ShapedType getSameShapeTensorType(ShapedType shapedType, Type elementType) {</span></a>
<a name="151"><span class="lineNum">     151 </span><span class="lineCov">      12772 :   if (auto rankedTensorTy = shapedType.dyn_cast&lt;RankedTensorType&gt;())</span></a>
<a name="152"><span class="lineNum">     152 </span><span class="lineCov">      25536 :     return RankedTensorType::get(rankedTensorTy.getShape(), elementType,</span></a>
<a name="153"><span class="lineNum">     153 </span><span class="lineCov">      12768 :                                  rankedTensorTy.getEncoding());</span></a>
<a name="154"><span class="lineNum">     154 </span><span class="lineCov">          4 :   if (auto unrankedTensorTy = shapedType.dyn_cast&lt;UnrankedTensorType&gt;())</span></a>
<a name="155"><span class="lineNum">     155 </span><span class="lineCov">          4 :     return UnrankedTensorType::get(elementType);</span></a>
<a name="156"><span class="lineNum">     156 </span><span class="lineNoCov">          0 :   llvm::report_fatal_error(&quot;unsupported type&quot;);</span></a>
<a name="157"><span class="lineNum">     157 </span><span class="lineCov">      12772 : }</span></a>
<a name="158"><span class="lineNum">     158 </span>            : </a>
<a name="159"><span class="lineNum">     159 </span>            : // createRealType takes a tensor type that may have complex elements and</a>
<a name="160"><span class="lineNum">     160 </span>            : // returns a type that maintains the shape, but with real numeric data types.</a>
<a name="161"><span class="lineNum">     161 </span>            : //   Ex: tensor&lt;4xcomplex&lt;f32&gt;&gt;  --&gt;  tensor&lt;4xf32&gt;</a>
<a name="162"><span class="lineNum">     162 </span><span class="lineCov">      11180 : ShapedType createRealType(ShapedType type) {</span></a>
<a name="163"><span class="lineNum">     163 </span><span class="lineCov">      11180 :   auto elementTy = type.getElementType();</span></a>
<a name="164"><span class="lineNum">     164 </span><span class="lineCov">      11180 :   if (auto complexTy = elementTy.dyn_cast&lt;ComplexType&gt;())</span></a>
<a name="165"><span class="lineNum">     165 </span><span class="lineCov">      11159 :     elementTy = complexTy.getElementType();</span></a>
<a name="166"><span class="lineNum">     166 </span><span class="lineCov">      11180 :   return hlo::getSameShapeTensorType(type, elementTy);</span></a>
<a name="167"><span class="lineNum">     167 </span><span class="lineCov">      11180 : }</span></a>
<a name="168"><span class="lineNum">     168 </span>            : </a>
<a name="169"><span class="lineNum">     169 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="170"><span class="lineNum">     170 </span>            : // Utils for shape functions with bounded dynamism.</a>
<a name="171"><span class="lineNum">     171 </span>            : //===----------------------------------------------------------------------===//</a>
<a name="172"><span class="lineNum">     172 </span>            : </a>
<a name="173"><span class="lineNum">     173 </span><span class="lineCov">        620 : LogicalResult verifyBounds(ArrayRef&lt;int64_t&gt; bounds, RankedTensorType type,</span></a>
<a name="174"><span class="lineNum">     174 </span><span class="lineCov">        620 :                            function_ref&lt;InFlightDiagnostic()&gt; emitError) {</span></a>
<a name="175"><span class="lineNum">     175 </span><span class="lineCov">        620 :   int64_t boundsLen = bounds.size();</span></a>
<a name="176"><span class="lineNum">     176 </span><span class="lineCov">        620 :   int64_t rank = type.getRank();</span></a>
<a name="177"><span class="lineNum">     177 </span><span class="lineCov">        620 :   if (boundsLen != rank)</span></a>
<a name="178"><span class="lineNum">     178 </span><span class="lineCov">          2 :     return emitError() &lt;&lt; &quot;Bounds length is &quot; &lt;&lt; boundsLen</span></a>
<a name="179"><span class="lineNum">     179 </span><span class="lineCov">          1 :                        &lt;&lt; &quot;, expected to be equal to rank(&quot; &lt;&lt; rank</span></a>
<a name="180"><span class="lineNum">     180 </span><span class="lineCov">          1 :                        &lt;&lt; &quot;) of the tensor&quot;;</span></a>
<a name="181"><span class="lineNum">     181 </span>            : </a>
<a name="182"><span class="lineNum">     182 </span><span class="lineCov">       2065 :   for (int64_t dim = 0; dim &lt; rank; ++dim) {</span></a>
<a name="183"><span class="lineNum">     183 </span><span class="lineCov">       1446 :     int64_t bound = bounds[dim];</span></a>
<a name="184"><span class="lineNum">     184 </span><span class="lineCov">       1446 :     int64_t dimSize = type.getDimSize(dim);</span></a>
<a name="185"><span class="lineNum">     185 </span><span class="lineCov">       1446 :     if (bound != ShapedType::kDynamic &amp;&amp; dimSize != ShapedType::kDynamic)</span></a>
<a name="186"><span class="lineNum">     186 </span><span class="lineCov">          2 :       return emitError() &lt;&lt; &quot;Static dimension &quot; &lt;&lt; dim</span></a>
<a name="187"><span class="lineNum">     187 </span><span class="lineCov">          1 :                          &lt;&lt; &quot; cannot have a bound, use ShapedType::kDynamic to &quot;</span></a>
<a name="188"><span class="lineNum">     188 </span>            :                             &quot;indicate a missing bound&quot;;</a>
<a name="189"><span class="lineNum">     189 </span><span class="lineCov">       1446 :   }</span></a>
<a name="190"><span class="lineNum">     190 </span>            : </a>
<a name="191"><span class="lineNum">     191 </span><span class="lineCov">        618 :   return success();</span></a>
<a name="192"><span class="lineNum">     192 </span><span class="lineCov">        620 : }</span></a>
<a name="193"><span class="lineNum">     193 </span>            : </a>
<a name="194"><span class="lineNum">     194 </span><span class="lineCov">    1277251 : ArrayRef&lt;int64_t&gt; encodingToBounds(Attribute encoding) {</span></a>
<a name="195"><span class="lineNum">     195 </span><span class="lineCov">    1277251 :   if (auto boundedAttr = encoding.dyn_cast_or_null&lt;BoundedAttrInterface&gt;())</span></a>
<a name="196"><span class="lineNum">     196 </span><span class="lineCov">        216 :     return boundedAttr.getBounds();</span></a>
<a name="197"><span class="lineNum">     197 </span><span class="lineCov">    1277036 :   return {};</span></a>
<a name="198"><span class="lineNum">     198 </span><span class="lineCov">    1277251 : }</span></a>
<a name="199"><span class="lineNum">     199 </span>            : </a>
<a name="200"><span class="lineNum">     200 </span><span class="lineCov">     713817 : Attribute boundsToEncoding(Attribute prototype, ArrayRef&lt;int64_t&gt; bounds) {</span></a>
<a name="201"><span class="lineNum">     201 </span><span class="lineCov">     713817 :   if (bounds.empty()) return prototype;</span></a>
<a name="202"><span class="lineNum">     202 </span><span class="lineCov">      23074 :   if (llvm::all_of(bounds, [&amp;](auto b) { return isDynamicDimSize(b); }))</span></a>
<a name="203"><span class="lineNum">     203 </span><span class="lineCov">       7440 :     return {};</span></a>
<a name="204"><span class="lineNum">     204 </span><span class="lineCov">         85 :   if (!prototype)</span></a>
<a name="205"><span class="lineNum">     205 </span><span class="lineNoCov">          0 :     llvm::report_fatal_error(</span></a>
<a name="206"><span class="lineNum">     206 </span>            :         &quot;Expect an prototype attribute to obtain the underlying dialect but &quot;</a>
<a name="207"><span class="lineNum">     207 </span>            :         &quot;got none&quot;);</a>
<a name="208"><span class="lineNum">     208 </span><span class="lineCov">         85 :   auto dialect = cast&lt;HloDialectInterface&gt;(&amp;prototype.getDialect());</span></a>
<a name="209"><span class="lineNum">     209 </span><span class="lineCov">         85 :   return dialect-&gt;createTypeExtensions(bounds);</span></a>
<a name="210"><span class="lineNum">     210 </span><span class="lineCov">     713817 : }</span></a>
<a name="211"><span class="lineNum">     211 </span>            : </a>
<a name="212"><span class="lineNum">     212 </span>            : // Inference rules to concat dimensions with bounds (lhs/rhs are commutative):</a>
<a name="213"><span class="lineNum">     213 </span>            : //       Dim of lhs     Dim of rhs      Infer</a>
<a name="214"><span class="lineNum">     214 </span>            : //  c0:  X              Y               X+Y</a>
<a name="215"><span class="lineNum">     215 </span>            : //  c1:  X              ?               ?</a>
<a name="216"><span class="lineNum">     216 </span>            : //  c2:  X              ?, B            ?, X+B</a>
<a name="217"><span class="lineNum">     217 </span>            : //  c3:  ?              ?               ?</a>
<a name="218"><span class="lineNum">     218 </span>            : //  c4:  ?              ?, B            ?</a>
<a name="219"><span class="lineNum">     219 </span>            : //  c5:  ?, B           ?, C            ?, B+C</a>
<a name="220"><span class="lineNum">     220 </span><span class="lineCov">     109681 : std::pair&lt;int64_t, int64_t&gt; inferConcatenatedDimAndBound(int64_t leftSize,</span></a>
<a name="221"><span class="lineNum">     221 </span>            :                                                          int64_t rightSize,</a>
<a name="222"><span class="lineNum">     222 </span>            :                                                          int64_t leftBound,</a>
<a name="223"><span class="lineNum">     223 </span><span class="lineCov">     109681 :                                                          int64_t rightBound) {</span></a>
<a name="224"><span class="lineNum">     224 </span><span class="lineCov">     109681 :   bool isLeftStaticDim = !isDynamicDimSize(leftSize);</span></a>
<a name="225"><span class="lineNum">     225 </span><span class="lineCov">     109681 :   bool isRightStaticDim = !isDynamicDimSize(rightSize);</span></a>
<a name="226"><span class="lineNum">     226 </span><span class="lineCov">     109681 :   int64_t inferredSize = ShapedType::kDynamic;</span></a>
<a name="227"><span class="lineNum">     227 </span><span class="lineCov">     109681 :   int64_t inferredBound = ShapedType::kDynamic;</span></a>
<a name="228"><span class="lineNum">     228 </span>            : </a>
<a name="229"><span class="lineNum">     229 </span><span class="lineCov">     109681 :   if (isLeftStaticDim &amp;&amp; isRightStaticDim) {</span></a>
<a name="230"><span class="lineNum">     230 </span><span class="lineCov">     109154 :     inferredSize = leftSize + rightSize;</span></a>
<a name="231"><span class="lineNum">     231 </span><span class="lineCov">     109154 :   } else {</span></a>
<a name="232"><span class="lineNum">     232 </span><span class="lineCov">        527 :     int64_t leftSizeOrBound = isLeftStaticDim ? leftSize : leftBound;</span></a>
<a name="233"><span class="lineNum">     233 </span><span class="lineCov">        527 :     int64_t rightSizeOrBound = isRightStaticDim ? rightSize : rightBound;</span></a>
<a name="234"><span class="lineNum">     234 </span><span class="lineCov">        527 :     if (!isDynamicDimSize(leftSizeOrBound) &amp;&amp;</span></a>
<a name="235"><span class="lineNum">     235 </span><span class="lineCov">        281 :         !isDynamicDimSize(rightSizeOrBound))</span></a>
<a name="236"><span class="lineNum">     236 </span><span class="lineCov">         24 :       inferredBound = leftSizeOrBound + rightSizeOrBound;</span></a>
<a name="237"><span class="lineNum">     237 </span><span class="lineCov">        527 :   }</span></a>
<a name="238"><span class="lineNum">     238 </span><span class="lineCov">     109681 :   return {inferredSize, inferredBound};</span></a>
<a name="239"><span class="lineNum">     239 </span><span class="lineCov">     109681 : }</span></a>
<a name="240"><span class="lineNum">     240 </span>            : </a>
<a name="241"><span class="lineNum">     241 </span>            : // Inference rules to merge dimensions with bounds (lhs/rhs are commutative):</a>
<a name="242"><span class="lineNum">     242 </span>            : //       Dim of lhs     Dim of rhs      Infer</a>
<a name="243"><span class="lineNum">     243 </span>            : //  c0:  X              X               X</a>
<a name="244"><span class="lineNum">     244 </span>            : //  c1:  X              ?               X</a>
<a name="245"><span class="lineNum">     245 </span>            : //  c2:  X              ?, B(&gt;=X)       X</a>
<a name="246"><span class="lineNum">     246 </span>            : //  c3:  X              ?, B(&lt;X)        Will error out by compatible checks</a>
<a name="247"><span class="lineNum">     247 </span>            : //  c4:  ?              ?               ?</a>
<a name="248"><span class="lineNum">     248 </span>            : //  c5:  ?              ?, B            ?, B</a>
<a name="249"><span class="lineNum">     249 </span>            : //  c6:  ?, B           ?, C            ?, min(B, C)</a>
<a name="250"><span class="lineNum">     250 </span><span class="lineCov">     634561 : FailureOr&lt;std::pair&lt;int64_t, int64_t&gt;&gt; inferMostSpecificDimAndBound(</span></a>
<a name="251"><span class="lineNum">     251 </span>            :     std::optional&lt;Location&gt; location, int64_t dim, int64_t leftSize,</a>
<a name="252"><span class="lineNum">     252 </span><span class="lineCov">     634561 :     int64_t rightSize, int64_t leftBound, int64_t rightBound) {</span></a>
<a name="253"><span class="lineNum">     253 </span><span class="lineCov">     634561 :   bool isLeftStaticDim = !isDynamicDimSize(leftSize);</span></a>
<a name="254"><span class="lineNum">     254 </span><span class="lineCov">     634561 :   bool isRightStaticDim = !isDynamicDimSize(rightSize);</span></a>
<a name="255"><span class="lineNum">     255 </span><span class="lineCov">     634561 :   bool isLeftStaticBound = !isDynamicDimSize(leftBound);</span></a>
<a name="256"><span class="lineNum">     256 </span><span class="lineCov">     634561 :   bool isRightStaticBound = !isDynamicDimSize(rightBound);</span></a>
<a name="257"><span class="lineNum">     257 </span><span class="lineCov">     634561 :   int64_t inferredSize = ShapedType::kDynamic;</span></a>
<a name="258"><span class="lineNum">     258 </span><span class="lineCov">     634561 :   int64_t inferredBound = ShapedType::kDynamic;</span></a>
<a name="259"><span class="lineNum">     259 </span>            : </a>
<a name="260"><span class="lineNum">     260 </span><span class="lineCov">     634561 :   if (isLeftStaticDim || isRightStaticDim) {</span></a>
<a name="261"><span class="lineNum">     261 </span><span class="lineCov">     615311 :     if (isLeftStaticDim &amp;&amp; isRightStaticDim &amp;&amp; leftSize != rightSize)</span></a>
<a name="262"><span class="lineNum">     262 </span><span class="lineCov">          2 :       return emitOptionalError(location, &quot;Mismatched dimension sizes &quot;,</span></a>
<a name="263"><span class="lineNum">     263 </span>            :                                leftSize, &quot; and &quot;, rightSize, &quot; in dimension &quot;,</a>
<a name="264"><span class="lineNum">     264 </span>            :                                dim);</a>
<a name="265"><span class="lineNum">     265 </span><span class="lineCov">     615309 :     inferredSize = isLeftStaticDim ? leftSize : rightSize;</span></a>
<a name="266"><span class="lineNum">     266 </span><span class="lineCov">     615309 :     if (isLeftStaticBound || isRightStaticBound) {</span></a>
<a name="267"><span class="lineNum">     267 </span><span class="lineCov">         16 :       int64_t check_bound = isLeftStaticBound ? leftBound : rightBound;</span></a>
<a name="268"><span class="lineNum">     268 </span><span class="lineCov">         16 :       if (inferredSize &gt; check_bound)</span></a>
<a name="269"><span class="lineNum">     269 </span><span class="lineNoCov">          0 :         return emitOptionalError(location, &quot;Mismatched dimension size &quot;,</span></a>
<a name="270"><span class="lineNum">     270 </span>            :                                  inferredSize, &quot; and bound &quot;, check_bound,</a>
<a name="271"><span class="lineNum">     271 </span>            :                                  &quot; in dimension &quot;, dim);</a>
<a name="272"><span class="lineNum">     272 </span><span class="lineCov">         16 :     }</span></a>
<a name="273"><span class="lineNum">     273 </span><span class="lineCov">     615309 :   } else {</span></a>
<a name="274"><span class="lineNum">     274 </span><span class="lineCov">      19250 :     if (isLeftStaticBound &amp;&amp; isRightStaticBound)</span></a>
<a name="275"><span class="lineNum">     275 </span><span class="lineCov">         22 :       inferredBound = std::min(leftBound, rightBound);</span></a>
<a name="276"><span class="lineNum">     276 </span>            :     else</a>
<a name="277"><span class="lineNum">     277 </span><span class="lineCov">      19228 :       inferredBound = isLeftStaticBound ? leftBound : rightBound;</span></a>
<a name="278"><span class="lineNum">     278 </span>            :   }</a>
<a name="279"><span class="lineNum">     279 </span><span class="lineCov">     634559 :   return std::make_pair(inferredSize, inferredBound);</span></a>
<a name="280"><span class="lineNum">     280 </span><span class="lineCov">     634561 : }</span></a>
<a name="281"><span class="lineNum">     281 </span>            : </a>
<a name="282"><span class="lineNum">     282 </span>            : // Inference rules for conditional branches (lhs/rhs are commutative):</a>
<a name="283"><span class="lineNum">     283 </span>            : //       Dim of lhs     Dim of rhs      Infer</a>
<a name="284"><span class="lineNum">     284 </span>            : //  c0:  X              X               X</a>
<a name="285"><span class="lineNum">     285 </span>            : //  c1:  X              ?               ?</a>
<a name="286"><span class="lineNum">     286 </span>            : //  c2:  X              ?, B            ?, max(X, B)</a>
<a name="287"><span class="lineNum">     287 </span>            : //  c3:  ?              ?               ?</a>
<a name="288"><span class="lineNum">     288 </span>            : //  c4:  ?              ?, B            ?</a>
<a name="289"><span class="lineNum">     289 </span>            : //  c5:  ?, B           ?, C            ?, max(B, C)</a>
<a name="290"><span class="lineNum">     290 </span><span class="lineCov">         75 : FailureOr&lt;std::pair&lt;int64_t, int64_t&gt;&gt; inferLeastSpecificDimAndBound(</span></a>
<a name="291"><span class="lineNum">     291 </span>            :     std::optional&lt;Location&gt; location, int64_t dim, int64_t leftSize,</a>
<a name="292"><span class="lineNum">     292 </span><span class="lineCov">         75 :     int64_t rightSize, int64_t leftBound, int64_t rightBound) {</span></a>
<a name="293"><span class="lineNum">     293 </span><span class="lineCov">         75 :   bool isLeftStaticDim = !isDynamicDimSize(leftSize);</span></a>
<a name="294"><span class="lineNum">     294 </span><span class="lineCov">         75 :   bool isRightStaticDim = !isDynamicDimSize(rightSize);</span></a>
<a name="295"><span class="lineNum">     295 </span><span class="lineCov">         75 :   bool isLeftStaticBound = !isDynamicDimSize(leftBound);</span></a>
<a name="296"><span class="lineNum">     296 </span><span class="lineCov">         75 :   bool isRightStaticBound = !isDynamicDimSize(rightBound);</span></a>
<a name="297"><span class="lineNum">     297 </span><span class="lineCov">         75 :   int64_t inferredSize = ShapedType::kDynamic;</span></a>
<a name="298"><span class="lineNum">     298 </span><span class="lineCov">         75 :   int64_t inferredBound = ShapedType::kDynamic;</span></a>
<a name="299"><span class="lineNum">     299 </span>            : </a>
<a name="300"><span class="lineNum">     300 </span><span class="lineCov">         75 :   if (isLeftStaticDim || isRightStaticDim) {</span></a>
<a name="301"><span class="lineNum">     301 </span><span class="lineCov">         61 :     if (isLeftStaticDim &amp;&amp; isRightStaticDim) {</span></a>
<a name="302"><span class="lineNum">     302 </span><span class="lineCov">         47 :       if (leftSize != rightSize)</span></a>
<a name="303"><span class="lineNum">     303 </span><span class="lineNoCov">          0 :         return emitOptionalError(location, &quot;Mismatched dimension sizes &quot;,</span></a>
<a name="304"><span class="lineNum">     304 </span>            :                                  leftSize, &quot; and &quot;, rightSize, &quot; in dimension &quot;,</a>
<a name="305"><span class="lineNum">     305 </span>            :                                  dim);</a>
<a name="306"><span class="lineNum">     306 </span><span class="lineCov">         47 :       inferredSize = leftSize;</span></a>
<a name="307"><span class="lineNum">     307 </span><span class="lineCov">         61 :     } else if (isLeftStaticBound || isRightStaticBound) {</span></a>
<a name="308"><span class="lineNum">     308 </span><span class="lineCov">          8 :       inferredBound = isLeftStaticDim ? std::max(leftSize, rightBound)</span></a>
<a name="309"><span class="lineNum">     309 </span><span class="lineNoCov">          0 :                                       : std::max(rightSize, leftBound);</span></a>
<a name="310"><span class="lineNum">     310 </span><span class="lineCov">          8 :     }</span></a>
<a name="311"><span class="lineNum">     311 </span><span class="lineCov">         75 :   } else if (isLeftStaticBound &amp;&amp; isRightStaticBound) {</span></a>
<a name="312"><span class="lineNum">     312 </span><span class="lineCov">          4 :     inferredBound = std::max(leftBound, rightBound);</span></a>
<a name="313"><span class="lineNum">     313 </span><span class="lineCov">          4 :   }</span></a>
<a name="314"><span class="lineNum">     314 </span><span class="lineCov">         75 :   return std::make_pair(inferredSize, inferredBound);</span></a>
<a name="315"><span class="lineNum">     315 </span><span class="lineCov">         75 : }</span></a>
<a name="316"><span class="lineNum">     316 </span>            : </a>
<a name="317"><span class="lineNum">     317 </span><span class="lineCov">     503915 : FailureOr&lt;ShapedType&gt; inferTypeWithCustomFn(</span></a>
<a name="318"><span class="lineNum">     318 </span>            :     std::optional&lt;Location&gt; location, SmallVector&lt;RankedTensorType&gt; rankedTypes,</a>
<a name="319"><span class="lineNum">     319 </span>            :     std::function&lt;FailureOr&lt;std::pair&lt;int64_t, int64_t&gt;&gt;(</a>
<a name="320"><span class="lineNum">     320 </span>            :         std::optional&lt;Location&gt;, int64_t, int64_t, int64_t, int64_t, int64_t)&gt;</a>
<a name="321"><span class="lineNum">     321 </span><span class="lineCov">     503915 :         inferDimAndBoundFn) {</span></a>
<a name="322"><span class="lineNum">     322 </span><span class="lineCov">     503915 :   auto rank = rankedTypes[0].getRank();</span></a>
<a name="323"><span class="lineNum">     323 </span><span class="lineCov">    1481598 :   for (auto&amp; type : rankedTypes) {</span></a>
<a name="324"><span class="lineNum">     324 </span><span class="lineCov">     977683 :     if (type.getRank() != rank) {</span></a>
<a name="325"><span class="lineNum">     325 </span><span class="lineNoCov">          0 :       return emitOptionalError(location, &quot;Mismatched ranks of types&quot;,</span></a>
<a name="326"><span class="lineNum">     326 </span><span class="lineNoCov">          0 :                                rankedTypes[0].getRank(), &quot; vs &quot;,</span></a>
<a name="327"><span class="lineNum">     327 </span><span class="lineNoCov">          0 :                                type.getRank());</span></a>
<a name="328"><span class="lineNum">     328 </span>            :     }</a>
<a name="329"><span class="lineNum">     329 </span><span class="lineCov">     977683 :   }</span></a>
<a name="330"><span class="lineNum">     330 </span><span class="lineCov">     504168 :   SmallVector&lt;int64_t&gt; inferredSizes = to_vector(rankedTypes[0].getShape());</span></a>
<a name="331"><span class="lineNum">     331 </span><span class="lineCov">     504168 :   SmallVector&lt;int64_t&gt; inferredBounds(rank, ShapedType::kDynamic);</span></a>
<a name="332"><span class="lineNum">     332 </span><span class="lineCov">     504168 :   ArrayRef&lt;int64_t&gt; bounds = encodingToBounds(rankedTypes[0].getEncoding());</span></a>
<a name="333"><span class="lineNum">     333 </span><span class="lineCov">     504168 :   if (!bounds.empty()) inferredBounds = to_vector(bounds);</span></a>
<a name="334"><span class="lineNum">     334 </span><span class="lineCov">     504168 :   bool anyInputHaveBounds = !bounds.empty();</span></a>
<a name="335"><span class="lineNum">     335 </span>            : </a>
<a name="336"><span class="lineNum">     336 </span><span class="lineCov">     978488 :   for (unsigned i = 1; i &lt; rankedTypes.size(); ++i) {</span></a>
<a name="337"><span class="lineNum">     337 </span><span class="lineCov">     474320 :     bounds = encodingToBounds(rankedTypes[i].getEncoding());</span></a>
<a name="338"><span class="lineNum">     338 </span><span class="lineCov">    1066624 :     for (int dim = 0; dim &lt; rank; ++dim) {</span></a>
<a name="339"><span class="lineNum">     339 </span><span class="lineCov">    1184608 :       auto inferredDimAndBoundOrErr = inferDimAndBoundFn(</span></a>
<a name="340"><span class="lineNum">     340 </span><span class="lineCov">     592304 :           location, dim,</span></a>
<a name="341"><span class="lineNum">     341 </span><span class="lineCov">     592304 :           /*leftSize=*/inferredSizes[dim],</span></a>
<a name="342"><span class="lineNum">     342 </span><span class="lineCov">     592304 :           /*rightSize=*/rankedTypes[i].getShape()[dim],</span></a>
<a name="343"><span class="lineNum">     343 </span><span class="lineCov">     592304 :           /*leftBound=*/inferredBounds[dim],</span></a>
<a name="344"><span class="lineNum">     344 </span><span class="lineCov">     592304 :           /*rightBound=*/bounds.empty() ? ShapedType::kDynamic : bounds[dim]);</span></a>
<a name="345"><span class="lineNum">     345 </span><span class="lineCov">     592304 :       if (failed(inferredDimAndBoundOrErr)) return failure();</span></a>
<a name="346"><span class="lineNum">     346 </span><span class="lineCov">     592302 :       inferredSizes[dim] = (*inferredDimAndBoundOrErr).first;</span></a>
<a name="347"><span class="lineNum">     347 </span><span class="lineCov">     592302 :       inferredBounds[dim] = (*inferredDimAndBoundOrErr).second;</span></a>
<a name="348"><span class="lineNum">     348 </span><span class="lineCov">     592304 :     }</span></a>
<a name="349"><span class="lineNum">     349 </span><span class="lineCov">     474139 :   }</span></a>
<a name="350"><span class="lineNum">     350 </span>            : </a>
<a name="351"><span class="lineNum">     351 </span><span class="lineCov">    1007788 :   return {RankedTensorType::get(</span></a>
<a name="352"><span class="lineNum">     352 </span><span class="lineCov">     503894 :       inferredSizes, rankedTypes[0].getElementType(),</span></a>
<a name="353"><span class="lineNum">     353 </span><span class="lineCov">     503894 :       boundsToEncoding(</span></a>
<a name="354"><span class="lineNum">     354 </span><span class="lineCov">     503894 :           rankedTypes[0].getEncoding(),</span></a>
<a name="355"><span class="lineNum">     355 </span>            :           // Empty array as argument is an indicator to boundsToEncoding() that</a>
<a name="356"><span class="lineNum">     356 </span>            :           // there are no bounds at all in inputs, thus sparsity attributes will</a>
<a name="357"><span class="lineNum">     357 </span>            :           // be included in the return type</a>
<a name="358"><span class="lineNum">     358 </span><span class="lineCov">     503894 :           anyInputHaveBounds ? inferredBounds : ArrayRef&lt;int64_t&gt;({})))};</span></a>
<a name="359"><span class="lineNum">     359 </span><span class="lineCov">     504421 : }</span></a>
<a name="360"><span class="lineNum">     360 </span>            : </a>
<a name="361"><span class="lineNum">     361 </span><span class="lineCov">        137 : FailureOr&lt;Type&gt; inferLeastSpecificType(std::optional&lt;Location&gt; location,</span></a>
<a name="362"><span class="lineNum">     362 </span><span class="lineCov">        137 :                                        TypeRange inputTypes) {</span></a>
<a name="363"><span class="lineNum">     363 </span><span class="lineCov">        137 :   SmallVector&lt;RankedTensorType&gt; rankedTypes;</span></a>
<a name="364"><span class="lineNum">     364 </span><span class="lineCov">        365 :   for (auto inputType : inputTypes)</span></a>
<a name="365"><span class="lineNum">     365 </span><span class="lineCov">        236 :     if (auto rankedType = inputType.dyn_cast&lt;RankedTensorType&gt;())</span></a>
<a name="366"><span class="lineNum">     366 </span><span class="lineCov">        220 :       rankedTypes.push_back(rankedType);</span></a>
<a name="367"><span class="lineNum">     367 </span>            :     else</a>
<a name="368"><span class="lineNum">     368 </span><span class="lineCov">        236 :       return inputType;</span></a>
<a name="369"><span class="lineNum">     369 </span><span class="lineCov">        258 :   return inferTypeWithCustomFn(location, rankedTypes,</span></a>
<a name="370"><span class="lineNum">     370 </span><span class="lineCov">        129 :                                inferLeastSpecificDimAndBound);</span></a>
<a name="371"><span class="lineNum">     371 </span><span class="lineCov">        137 : }</span></a>
<a name="372"><span class="lineNum">     372 </span>            : </a>
<a name="373"><span class="lineNum">     373 </span><span class="lineCov">     503788 : FailureOr&lt;Type&gt; inferMostSpecificType(std::optional&lt;Location&gt; location,</span></a>
<a name="374"><span class="lineNum">     374 </span><span class="lineCov">     503788 :                                       TypeRange inputTypes) {</span></a>
<a name="375"><span class="lineNum">     375 </span><span class="lineCov">     503788 :   SmallVector&lt;RankedTensorType&gt; rankedTypes;</span></a>
<a name="376"><span class="lineNum">     376 </span><span class="lineCov">    1480369 :   for (auto inputType : inputTypes)</span></a>
<a name="377"><span class="lineNum">     377 </span><span class="lineCov">     976581 :     if (auto rankedType = inputType.dyn_cast&lt;RankedTensorType&gt;())</span></a>
<a name="378"><span class="lineNum">     378 </span><span class="lineCov">     976581 :       rankedTypes.push_back(rankedType);</span></a>
<a name="379"><span class="lineNum">     379 </span><span class="lineCov">     503692 :   if (rankedTypes.empty()) return inputTypes[0];</span></a>
<a name="380"><span class="lineNum">     380 </span><span class="lineCov">    1007356 :   return inferTypeWithCustomFn(location, rankedTypes,</span></a>
<a name="381"><span class="lineNum">     381 </span><span class="lineCov">     503678 :                                inferMostSpecificDimAndBound);</span></a>
<a name="382"><span class="lineNum">     382 </span><span class="lineCov">     503692 : }</span></a>
<a name="383"><span class="lineNum">     383 </span>            : </a>
<a name="384"><span class="lineNum">     384 </span><span class="lineCov">      60925 : LogicalResult inferMostSpecificTypeComponents(</span></a>
<a name="385"><span class="lineNum">     385 </span>            :     std::optional&lt;Location&gt; location, TypeRange inputTypes,</a>
<a name="386"><span class="lineNum">     386 </span><span class="lineCov">      60925 :     SmallVectorImpl&lt;ShapedTypeComponents&gt;&amp; inferredReturnShapes) {</span></a>
<a name="387"><span class="lineNum">     387 </span><span class="lineCov">      60925 :   auto inferredTypeOrErr = inferMostSpecificType(location, inputTypes);</span></a>
<a name="388"><span class="lineNum">     388 </span><span class="lineCov">      60925 :   if (failed(inferredTypeOrErr)) return failure();</span></a>
<a name="389"><span class="lineNum">     389 </span>            : </a>
<a name="390"><span class="lineNum">     390 </span><span class="lineCov">      60925 :   auto rankedResultType = (*inferredTypeOrErr).dyn_cast&lt;RankedTensorType&gt;();</span></a>
<a name="391"><span class="lineNum">     391 </span><span class="lineCov">      60925 :   if (!rankedResultType) {</span></a>
<a name="392"><span class="lineNum">     392 </span><span class="lineNoCov">          0 :     auto inferredShapeType = (*inferredTypeOrErr).dyn_cast&lt;ShapedType&gt;();</span></a>
<a name="393"><span class="lineNum">     393 </span><span class="lineNoCov">          0 :     if (!inferredShapeType) return failure();</span></a>
<a name="394"><span class="lineNum">     394 </span><span class="lineNoCov">          0 :     inferredReturnShapes.emplace_back(inferredShapeType);</span></a>
<a name="395"><span class="lineNum">     395 </span><span class="lineNoCov">          0 :   } else {</span></a>
<a name="396"><span class="lineNum">     396 </span><span class="lineCov">     121850 :     inferredReturnShapes.emplace_back(rankedResultType.getShape(),</span></a>
<a name="397"><span class="lineNum">     397 </span><span class="lineCov">      60925 :                                       rankedResultType.getElementType(),</span></a>
<a name="398"><span class="lineNum">     398 </span><span class="lineCov">      60925 :                                       rankedResultType.getEncoding());</span></a>
<a name="399"><span class="lineNum">     399 </span>            :   }</a>
<a name="400"><span class="lineNum">     400 </span>            : </a>
<a name="401"><span class="lineNum">     401 </span><span class="lineCov">      60925 :   return success();</span></a>
<a name="402"><span class="lineNum">     402 </span><span class="lineCov">      60925 : }</span></a>
<a name="403"><span class="lineNum">     403 </span>            : </a>
<a name="404"><span class="lineNum">     404 </span><span class="lineCov">         22 : LogicalResult getShapeRefinements(</span></a>
<a name="405"><span class="lineNum">     405 </span>            :     std::optional&lt;Location&gt; location, Operation* op,</a>
<a name="406"><span class="lineNum">     406 </span><span class="lineCov">         22 :     SmallVector&lt;ShapedTypeComponents&gt;&amp; refinements) {</span></a>
<a name="407"><span class="lineNum">     407 </span><span class="lineCov">         44 :   auto indicesAttr = op-&gt;getAttr(&quot;indices_of_shape_operands&quot;)</span></a>
<a name="408"><span class="lineNum">     408 </span><span class="lineCov">         22 :                          .dyn_cast_or_null&lt;DenseIntElementsAttr&gt;();</span></a>
<a name="409"><span class="lineNum">     409 </span><span class="lineCov">         22 :   if (!indicesAttr) return failure();</span></a>
<a name="410"><span class="lineNum">     410 </span>            : </a>
<a name="411"><span class="lineNum">     411 </span><span class="lineCov">         13 :   if (indicesAttr.getNumElements() != op-&gt;getNumResults())</span></a>
<a name="412"><span class="lineNum">     412 </span><span class="lineCov">          2 :     return emitOptionalError(location, &quot;indices_of_shape_operands: number of &quot;,</span></a>
<a name="413"><span class="lineNum">     413 </span><span class="lineCov">          1 :                              &quot;elements (&quot;, indicesAttr.getNumElements(), &quot;) &quot;,</span></a>
<a name="414"><span class="lineNum">     414 </span>            :                              &quot;must be equal to the number of operation results&quot;,</a>
<a name="415"><span class="lineNum">     415 </span><span class="lineCov">          1 :                              &quot; (&quot;, op-&gt;getNumResults(), &quot;)&quot;);</span></a>
<a name="416"><span class="lineNum">     416 </span><span class="lineCov">         12 :   if (indicesAttr.getType().getRank() != 1)</span></a>
<a name="417"><span class="lineNum">     417 </span><span class="lineCov">          1 :     return emitOptionalError(location, &quot;indices_of_shape_operands: must have &quot;,</span></a>
<a name="418"><span class="lineNum">     418 </span>            :                              &quot;rank = 1&quot;);</a>
<a name="419"><span class="lineNum">     419 </span><span class="lineCov">         11 :   if (!indicesAttr.getType().getElementType().isInteger(64))</span></a>
<a name="420"><span class="lineNum">     420 </span><span class="lineCov">          1 :     return emitOptionalError(location, &quot;indices_of_shape_operands: must have &quot;,</span></a>
<a name="421"><span class="lineNum">     421 </span>            :                              &quot;i64 element type&quot;);</a>
<a name="422"><span class="lineNum">     422 </span>            : </a>
<a name="423"><span class="lineNum">     423 </span><span class="lineCov">         10 :   auto resultIndex = 0;</span></a>
<a name="424"><span class="lineNum">     424 </span><span class="lineCov">         39 :   for (auto [operandIndex, resultType] :</span></a>
<a name="425"><span class="lineNum">     425 </span><span class="lineCov">         10 :        llvm::zip(indicesAttr.getValues&lt;int64_t&gt;(), op-&gt;getResultTypes())) {</span></a>
<a name="426"><span class="lineNum">     426 </span><span class="lineCov">         15 :     if (operandIndex &lt; 0 || operandIndex &gt;= op-&gt;getNumOperands())</span></a>
<a name="427"><span class="lineNum">     427 </span><span class="lineCov">          2 :       return emitOptionalError(location, &quot;indices_of_shape_operands: index #&quot;,</span></a>
<a name="428"><span class="lineNum">     428 </span>            :                                resultIndex, &quot; (&quot;, operandIndex, &quot;) &quot;,</a>
<a name="429"><span class="lineNum">     429 </span>            :                                &quot;must be within bounds for operation operands &quot;,</a>
<a name="430"><span class="lineNum">     430 </span><span class="lineCov">          1 :                                &quot;(from 0 to &quot;, op-&gt;getNumOperands(), &quot;)&quot;);</span></a>
<a name="431"><span class="lineNum">     431 </span>            : </a>
<a name="432"><span class="lineNum">     432 </span><span class="lineCov">         28 :     Value operand = op-&gt;getOperand(operandIndex);</span></a>
<a name="433"><span class="lineNum">     433 </span><span class="lineCov">         14 :     SmallVector&lt;int64_t&gt; refinement;</span></a>
<a name="434"><span class="lineNum">     434 </span><span class="lineCov">         14 :     if (failed(hlo::matchInts(operand, refinement))) return failure();</span></a>
<a name="435"><span class="lineNum">     435 </span><span class="lineCov">         26 :     if (!isCompatibleForHloTypeInference(operand, resultType))</span></a>
<a name="436"><span class="lineNum">     436 </span><span class="lineCov">          1 :       return emitOptionalError(</span></a>
<a name="437"><span class="lineNum">     437 </span><span class="lineCov">          1 :           location, &quot;indices_of_shape_operands: refinement #&quot;, resultIndex,</span></a>
<a name="438"><span class="lineNum">     438 </span>            :           &quot; ([&quot;, refinement, &quot;]) must be compatible with operation result (&quot;,</a>
<a name="439"><span class="lineNum">     439 </span>            :           resultType, &quot;)&quot;);</a>
<a name="440"><span class="lineNum">     440 </span><span class="lineCov">         12 :     refinements.emplace_back(refinement);</span></a>
<a name="441"><span class="lineNum">     441 </span><span class="lineCov">         12 :     ++resultIndex;</span></a>
<a name="442"><span class="lineNum">     442 </span><span class="lineCov">         15 :   }</span></a>
<a name="443"><span class="lineNum">     443 </span><span class="lineCov">          7 :   return success();</span></a>
<a name="444"><span class="lineNum">     444 </span><span class="lineCov">         22 : }</span></a>
<a name="445"><span class="lineNum">     445 </span>            : </a>
<a name="446"><span class="lineNum">     446 </span>            : }  // namespace hlo</a>
<a name="447"><span class="lineNum">     447 </span>            : }  // namespace mlir</a>
</pre>
      </td>
    </tr>
  </table>
  <br>

  <table width="100%" border=0 cellspacing=0 cellpadding=0>
    <tr><td class="ruler"><img src="../../glass.png" width=3 height=3 alt=""></td></tr>
    <tr><td class="versionInfo">Generated by: <a href="https://github.com/linux-test-project/lcov" target="_parent">LCOV version 1.16</a></td></tr>
  </table>
  <br>

</body>
</html>
